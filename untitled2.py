# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NYT-HJKEL_J2gdbBcHJAHyWJG-kkyDSv

### **SVM Algorithm**

**Import Libraries**
"""

#Import The Neccesary Libaries
import glob
import os
import librosa
import time
import numpy as np
import pandas as pd

"""**Defining Emotions To Be Classified**"""

#Defining Different Emotions To Classify
 emotions={
     '01':'neutral',
     '02':'calm',
     '03':'happy',
     '04':'sad',
     '05':'angry',
     '06':'fear',
     '07':'disgust',
     '08':'suprised'

 }

 tess_emotions=['angry','disgust','fear','ps','happy','sad']

 ravdess_emotions=['neutral','calm','angry','happy','disgust','sad','fear','suprised']

 observed_emotions=['sad','angry','happy','disgust','suprised','neutral','calm','fear']

"""***Feature Extraction ***

Using The Librosa Package we extract all the different features and hence return the extracted features
"""

#Feature Extraction 
  def extract_feature(file_name, mfcc,chroma,mel):
    X, sample_rate=librosa.load(os.path.join(file_name), res_type='kaiser_fast')
    if chroma:
     stft=np.abs(librosa.stft(X))
     result=np.array([])
    if mfcc:
      mfcc=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
      result=np.hstack((result,mfcc))
    
    if chroma:
     chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)
     result=np.hstack((result,chroma))
    if mel:
      mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)
      result=np.hstack((result,mel))
    return result

"""**Choosing A Dataset**

Choose the dataset you want to load using the function defined below
"""

#Choosing A Dataset
def dataset_options():
    #choose datasets
    ravdess = True
    tess = True
    ravdess_speech=False
    ravdess_song=False
    data={'ravdess':ravdess, 'tess':tess}
    print(data)
    return data
  
#'ravdess_speech':CombinedActors, 'ravdess_song':CombinedActors,

from google.colab import drive

 drive.mount('/content/drive')

"""**Load Data**"""

#Loading Data From The Datasets Available 
def load_data(test_size=0.2):
    x,y=[],[]

    #feature to extract
    mfcc= True
    chroma= True
    mel= True
    data=dataset_options()
    paths=[]
    if data['ravdess']:
      #paths.append('..\Audio Emotion Recognition\CombinedActors\*.wav')
#   elif data['ravdess_speech']:
#     paths.append('..\Audio Emotion Recognition\CombinedActors\*.wav')
#   elif data['ravdess_song']:
#     paths.append('..\Audio Emotion Recognition\CombinedActors\*.wav')

    #for path in paths:
      for file in glob.glob('/content/drive/My Drive/Audio Emotion Recognition/CombinedActors/*.wav'):
          file_name=os.path.basename(file)
          emotion=emotions[file_name.split("-")[2]]
          if emotion not in observed_emotions:
            continue
          feature=extract_feature(file, mfcc, chroma, mel)
          x.append(feature)
          y.append(emotion)
  
    if data['tess']:
      for file in glob.glob('/content/drive/My Drive/Audio Emotion Recognition/TESS Dataset/TESS Toronto emotional speech set data/*AF_*/*.wav'):
          file_name=os.path.basename(file)
          emotion=file_name.split("_")[2][:-4]
          if emotion == 'ps':
              emotion='suprised'
          if emotion not in observed_emotions:
              continue
          feature=extract_feature(file, mfcc, chroma, mel)
          x.append(feature)
          y.append(emotion)    
    return {"X":x, "y":y}

start_time=time.time()

  Trial_dict=load_data(test_size=0.3)

  print("--- Data Loaded. Loading time: %s seconds ---" % (time.time() - start_time))

X=pd.DataFrame(Trial_dict["X"])
  y=pd.DataFrame(Trial_dict["y"])

X.shape, y.shape

"""**SVM Algorithm For Training The Obtained Dataset**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC

X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.20)

steps=[('scaler', StandardScaler()),
       ('SVM', SVC())]

pipeline=Pipeline(steps)

svc_scaled= pipeline.fit(X_train, y_train)

svc_unscaled=SVC(kernel='linear').fit(X_train, y_train)

print('Accuracy With Scaling {}'.format(svc_scaled.score(X_test,y_test)))
print('Accuracy Without Scaling {}'.format(svc_unscaled.score(X_test,y_test)))

train_acc = float(svc_scaled.score(X_train, y_train)*100)
print("---- Train Accuracy Score %s----"%train_acc)

test_acc = float(svc_scaled.score(X_test, y_test)*100)
print("---- Test Accuracy Score %s----"%test_acc)

scaled_predictions = svc_scaled.predict(X_test)

"""**Classification Report And Confusion Matrix**"""

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sn

print(classification_report(y_test, scaled_predictions))

acc= float(accuracy_score(y_test,scaled_predictions))*100

print("----Accuracy Score %s----" %acc)

cm=confusion_matrix(y_test, scaled_predictions)
df_cm=pd.DataFrame(cm)
sn.heatmap(df_cm, annot=True, fmt='')
plt.show()

!pip install ffmpeg-python

filename = "/content/drive/My Drive/Audio Emotion Recognition/CombinedActors/03-01-05-01-01-02-07.wav"# record the file (start talking)
    #record_to_file(filename)
    # extract features and reshape it
features = extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1)
    # predict
result = svc_scaled.predict(features)[0]
    # show the result !
print("result:", result)

import pickle

# Saving model to disk
pickle.dump(svc_scaled, open('svc_scaled.pkl','wb'))

# Loading model to compare the results
model = pickle.load(open('svc_scaled.pkl','rb'))
print(svc_scaled.predict(X_test))

from google.colab import files
files.download('svc_scaled.pkl')