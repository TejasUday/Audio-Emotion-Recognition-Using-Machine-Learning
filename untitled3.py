# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16JZHWfsl6OPTB2WKk-9gZ-0bzSlUUSti
"""

from google.colab import drive

drive.mount('/content/drive')

!pip install librosa soundfile numpy sklearn pyaudio

!pip install soundfile

import glob
   import os
   import librosa
   import soundfile
   import pickle
   import numpy as np
   from sklearn.model_selection import train_test_split
   from sklearn.neural_network import MLPClassifier
   from sklearn.metrics import accuracy_score

def extract_feature(file_name, mfcc, chroma,mel):
    X, sample_rate=librosa.load(os.path.join(file_name), res_type='kaiser_fast')
    if chroma:
      stft=np.abs(librosa.stft(X))
    result=np.array([])
    if mfcc:
      mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
      result=np.hstack((result,mfccs))
    if chroma:
      chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)
      result=np.hstack((result,chroma))
    if mel:
      mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)
      result=np.hstack((result,mel))

    return result

#Emotions In Ravdess And TESS Dataset
   emotions={
        '01':'neutral',
        '02':'calm',
        '03':'happy',
        '04':'sad',
        '05':'angry',
        '06':'fearful',
        '07':'disgust',
        '08':'suprised'

    }

   #Emotions To Observe
   observed_emotions=['neutral','calm','happy','sad','angry','fearful','disgust','suprised']

#Choosing A Dataset
def dataset_options():
    #choose datasets
    ravdess = True
    tess = True
    ravdess_speech=False
    ravdess_song=False
    data={'ravdess':ravdess, 'tess':tess}
    print(data)
    return data

def load_data(test_size=0.2):                                                                                                                                                                   
    x,y=[],[]
    #feature to extract
    mfcc= True
    chroma= True
    mel= True
    data=dataset_options()
    paths=[]

    if data['ravdess']:
     for file in glob.glob('/content/drive/My Drive/Audio Emotion Recognition/CombinedActors/*.wav'):
       file_name=os.path.basename(file)
       emotion=emotions[file_name.split("-")[2]]
       if emotion not in observed_emotions:
         continue
       feature=extract_feature(file,mfcc=True, chroma=True, mel=True)
       x.append(feature)
       y.append(emotion)
    if data['tess']:
     for file in glob.glob('/content/drive/My Drive/Audio Emotion Recognition/TESS Dataset/TESS Toronto emotional speech set data/*AF_*/*.wav'):
      file_name=os.path.basename(file)
      emotion=file_name.split("_")[2][:-4]
      if emotion == 'ps':
          emotion='suprised'
      if emotion not in observed_emotions:
          continue
      feature=extract_feature(file, mfcc, chroma, mel)
      x.append(feature)
      y.append(emotion)
    return train_test_split(np.array(x),y,test_size=test_size,train_size=0.8,random_state=9)

import time
  x_train,x_test,y_train,y_test=load_data(test_size=0.2)

print((x_train.shape[0], x_test.shape[0]))

print(f'Features Extracted:{x_train.shape[1]}')

model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)

model.fit(x_train,y_train)

y_pred=model.predict(x_test)

accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)

  print("Accuracy:{:.2f}%".format(accuracy*100))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(classification_report(y_test, y_pred))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

matrix=confusion_matrix(y_test, y_pred)

print(matrix)

import matplotlib.pyplot as plt
import seaborn as sn
import pandas as pd
df_matrix=pd.DataFrame(matrix)
sn.heatmap(df_matrix, annot=True, fmt='')
plt.show()

!pip install ffmpeg-python

filename = "/content/drive/My Drive/Audio Emotion Recognition/CombinedActors/03-01-05-01-01-02-07.wav"# record the file (start talking)
    #record_to_file(filename)
    # extract features and reshape it
features = extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1)
    # predict
result = model.predict(features)[0]
    # show the result !
print("result:", result)

import pickle

# Saving model to disk
pickle.dump(model, open('model.pkl','wb'))

# Loading model to compare the results
model = pickle.load(open('model.pkl','rb'))
print(model.predict(x_test))

from google.colab import files
files.download('model.pkl')

